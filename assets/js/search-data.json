{
  
    
        "post0": {
            "title": "Poker Combinatorics with Itertools",
            "content": "Suppose you&#39;re playing No Limit Hold&#39;em, and based on how your opponent has played the hand, you believe they have pocket aces, pocket kings, or ace-king. How likely is each hand? (Hint: They&#39;re not equally likely!) . The math that determines the likelihood of each hand is called combinatorics and it&#39;s in a sweet spot of being non-obvious, yet pretty easy to understand, and highly relevant for in-game strategy. I just finished Fluent Python by Luciano Ramalho and got a refresher on the Python built-in itertools module. It&#39;s the perfect way to explore poker combinations. . import itertools . The first example in the book is actually a playing card deck, so we can borrow a little code to get started. . suits = &#39;spades hearts diamonds clubs&#39;.split() ranks = [str(n) for n in range(2, 11)] + list(&#39;JQKA&#39;) . To get the cards in the deck, you can use the product function from itertools. Here&#39;s the description: . &quot;Cartesian product: yields N-tuples made by combining items from each input iterable like nested for loops could produce.&quot; . cards = list(itertools.product(ranks, suits)) . All the itertools functions return iterators, so if you want to do things like check the length, you need to coerce the result into a list. . len(cards) . 52 . cards[0], cards[-1] . ((&#39;2&#39;, &#39;spades&#39;), (&#39;A&#39;, &#39;clubs&#39;)) . Story checks out! . Now, combinations (or combos) are all the ways you can deal a two-card starting hand. Conveniently, itertools has a combinations function. . combos = list(itertools.combinations(cards, 2)) . len(combos) . 1326 . There are 1326 combinations, but these include combinations that you would typically consider the same hand. . combos[0] . ((&#39;2&#39;, &#39;spades&#39;), (&#39;2&#39;, &#39;hearts&#39;)) . combos[1] . ((&#39;2&#39;, &#39;spades&#39;), (&#39;2&#39;, &#39;diamonds&#39;)) . Even though the above hands have different cards, you&#39;d probably think of both of them as &quot;pocket deuces.&quot; . If you play a lot of poker, you&#39;ve likely seen &quot;The Grid,&quot; which is a more intuitive way of representing hands. . . In this way of representing the hands, the upper right hands are suited, the lower left are offsuit, and the pairs go diagonally across the middle. . To get something more like the grid representation of hands, you can take the product of ranks with itself. . hands = list(itertools.product(ranks, ranks)) . len(hands) . 169 . hands[0] . (&#39;2&#39;, &#39;2&#39;) . hands[-1] . (&#39;A&#39;, &#39;A&#39;) . How likely a hand is depends on how many ways it can be dealt - the combinations. You now have all the information you need to answer the initial question: If you think your opponent has pocket aces, pocket kings, or ace-king, how likely is each? . aces = [(&#39;A&#39;, s) for s in suits] kings = [(&#39;K&#39;, s) for s in suits] . AA = list(itertools.combinations(aces, 2)) KK = list(itertools.combinations(kings, 2)) . len(AA) . 6 . AA . [((&#39;A&#39;, &#39;spades&#39;), (&#39;A&#39;, &#39;hearts&#39;)), ((&#39;A&#39;, &#39;spades&#39;), (&#39;A&#39;, &#39;diamonds&#39;)), ((&#39;A&#39;, &#39;spades&#39;), (&#39;A&#39;, &#39;clubs&#39;)), ((&#39;A&#39;, &#39;hearts&#39;), (&#39;A&#39;, &#39;diamonds&#39;)), ((&#39;A&#39;, &#39;hearts&#39;), (&#39;A&#39;, &#39;clubs&#39;)), ((&#39;A&#39;, &#39;diamonds&#39;), (&#39;A&#39;, &#39;clubs&#39;))] . There are six ways to deal pocket aces. The same applies for pocket kings, or any other pair, of course. The chances of being dealt pocket aces are six divided by the total number of combinations. . len(AA) / len(combos) . 0.004524886877828055 . You get dealt pocket aces about one in 200 hands. . AK = list(itertools.product(aces, kings)) . len(AK) . 16 . There are 16 combinations of AK. Of those, some are suited and some are offsuit. . AKs = [h for h in AK if h[0][1] == h[1][1]] AKo = [h for h in AK if h[0][1] != h[1][1]] . len(AKs), len(AKo) . (4, 12) . Given that there are 16 combos of AK and only 6 each of AA and KK, AK is more likely than AA and KK combined. Given that 22 is actually a slight favorite against AK, if you hold 22 in this situation, you are actually ahead more often than not. Unfortunately, this is a classic slightly ahead/way behind scenario: you&#39;re either a tiny favorite or a huge underdog, so you&#39;re still basically screwed. But that&#39;s a topic for another day. . Takeaways . Not all hands are equally likely. | Offsuit, unpaired hands are the most likely. Pairs are less likely. Suited hands are the rarest are all. | This means, if you are considering whether it&#39;s likely for your opponent to have a certain hand, it&#39;s really important whether or not they would play the offsuit flavor of that hand. | .",
            "url": "https://natesolon.github.io/blog/combos",
            "relUrl": "/combos",
            "date": " • Jan 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Performance by Game Phase",
            "content": "I&#39;ve always had a sneaking suspicion that I suck at endgames. Certainly, I can remember many endgames that I&#39;ve painfully screwed up. But if there&#39;s one thing I&#39;ve learned from poker, it&#39;s that our memory of what happened over many games can differ wildly from reality when checked against hard data. . It shouldn&#39;t be too hard to check my intuition about being bad at the endgame against reality. Here&#39;s the plan: . Download my latest 1000 blitz games from lichess. | Use an engine to evaluate the position after each move. | Plot the difference of the evaluations move-by-move. This should allow me to see whether, on average, my position improved or got worse at each stage of the game. | import chess import chess.engine import matplotlib.pyplot as plt import numpy as np import pandas as pd import re import requests . Download Games . I&#39;ll take advantage of the lichess API to grab my last 1000 blitz games. If you want to use this notebook to analyze your own games, simply fill in your own lichess username. The token is a lichess personal API token. This is optional, but recommended, because otherwise downloading 1000 games is pretty slow. You could also use fewer games, of course, but more games is better because the move-by-move data is pretty noisy. . username = &#39;CheckRaiseMate&#39; token = &#39;F645u9pRLoxrEuHZ&#39; . def get_pgn(username, params={}, token=None): headers = {} if token is None else {&#39;Authorization&#39;: &#39;Bearer &#39; + token} r = requests.get(f&#39;https://lichess.org/api/games/user/{username}&#39;, params=params, headers=headers) pgn = r.text return pgn . params = dict( perfType=&#39;blitz&#39;, max=1000 ) . pgn = get_pgn(username, params=params, token=token) . with open(f&#39;{username}.pgn&#39;, &#39;w&#39;) as f: f.write(pgn) . games = pgn.split(&#39; n n n&#39;)[:-1] . len(games) . 1000 . Analyze Games . To evaluate the games I&#39;ll use the latest version of Stockfish. Fortunately, the python-chess library has an engine module that makes it easy to work with the engine in Python. . First I define a helper function to check which color I was in each game. This is important, because since the analysis is from my point-of-view, in games where I was black I&#39;ll need to flip the engine evaluation. . def get_color(username, game): wp = re.compile(&#39;White &quot;(.+?)&quot;&#39;) result = wp.search(game) white = result.group(1) bp = re.compile(&#39;Black &quot;(.+?)&quot;&#39;) result = bp.search(game) black = result.group(1) if white == username: return 0 elif black == username: return 1 else: return None . Then I go through all the games and get the engine evaluation after each move. There are a few tricks here... . I decided to only run the evaluation after my own moves. It wasn&#39;t clear to me if this would be better than evaluating after my opponent&#39;s moves as well, but it does cut the number of positions I need to evaluate in half and it takes awhile to evaluate every move in 1000 games. . Then you need to set some parameters for the engine. The first is how much time to give it to think about each position. 0.1 seconds seems like a decent balance between accuracy and speed. I don&#39;t think ultra-precise evaluations are that important when you&#39;re looking at broad trends across many games. . Then there&#39;s mate score and max score. The engine gives evaluations in centipawns (100 centipawns = 1 pawn) and you need to choose a numeric value to use for a checkmate position - presumably a very large value - which is the mate score. I also felt that differences in scores above a certain threshold aren&#39;t very meaningful. For example, a +10 and +20 position are both completely winning, but a difference of 10 in the evaluation is huge and really messes up summary statistics. For that reason, I clipped the evaluations at +/- 1000 centipawns (10 pawns). I ended up doing more to address this problem, but more on that later. . def evaluate_game(game, engine, username, time=0.1, max_score=1000): board = chess.Board() color = get_color(username, game) moves = game.split(&#39; n&#39;)[-1] moves = re.sub(&quot;[0-9]* .&quot;, &quot;&quot;, moves).split()[:-1] # remove move numbers evals = [] for i, move in enumerate(moves): board.push_san(move) if i%2 == color: # get eval only after my move info = engine.analyse(board, chess.engine.Limit(time=time)) eval = info[&#39;score&#39;].white().score(mate_score=max_score) eval = np.clip(eval, -max_score, max_score) if color == 1: eval *= -1 eval /= 100 evals.append(eval) return evals . engine_path = &quot;/usr/local/Cellar/stockfish/12/bin/stockfish&quot; engine = chess.engine.SimpleEngine.popen_uci(engine_path) all_evals = [] for i, game in enumerate(games): if i%100==0: print(f&quot;Game {i}&quot;) evals = evaluate_game(game, engine, username) all_evals.append(evals) engine.quit() . Game 0 Game 100 Game 200 Game 300 Game 400 Game 500 Game 600 Game 700 Game 800 Game 900 . To make analysis easier, I put all the evaluations in a pandas dataframe. Each column is one game, the rows are moves, and each cell is an evaluation. . df = pd.concat([pd.Series(e) for e in all_evals], axis=1) . df.shape . (121, 1000) . df.head() . 0 1 2 3 4 5 6 7 8 9 ... 990 991 992 993 994 995 996 997 998 999 . 0 -0.27 | 0.32 | 0.31 | -0.30 | 0.16 | 0.24 | 0.22 | -0.30 | -0.25 | 0.04 | ... | 0.10 | -0.10 | -0.24 | 0.08 | -0.33 | 0.05 | 0.17 | -0.50 | 0.18 | -0.30 | . 1 -0.17 | 0.35 | 0.69 | -0.10 | 0.23 | 0.25 | 0.26 | -0.40 | -0.15 | 0.27 | ... | 0.12 | -0.18 | -0.57 | 0.08 | -0.22 | -0.33 | 0.09 | -0.29 | 0.13 | -0.46 | . 2 -0.21 | 0.63 | 0.68 | -0.16 | 0.70 | 0.37 | 0.61 | -0.44 | 0.01 | 0.23 | ... | 0.21 | -0.37 | -0.49 | 0.00 | -0.31 | -0.36 | 0.12 | -0.44 | 0.34 | -0.42 | . 3 -0.39 | 0.90 | 1.13 | -0.28 | 0.54 | 0.24 | 0.48 | -0.18 | -0.14 | 1.21 | ... | 0.25 | 0.01 | -0.56 | 0.08 | -0.05 | -0.21 | 0.03 | -0.19 | 0.69 | -0.75 | . 4 -0.19 | 0.72 | 0.80 | -0.22 | 0.44 | 0.36 | 0.47 | -0.34 | 0.21 | 1.18 | ... | 0.23 | 0.08 | -0.65 | 0.21 | 0.47 | 0.04 | 0.08 | -0.10 | 0.43 | -0.90 | . 5 rows × 1000 columns . df.to_csv(&#39;evals.csv&#39;, index=False) . First let&#39;s look at the mean across all columns. This is the average evaluation by move number across all games. . df.mean(axis=1)[:60].plot(); . It starts at 0.0 (equal position) and gradually goes up. This makes sense, because I win more games than I lose on lichess, so in general the evaluation should go up as the game goes on. Maybe I would improve at chess more quickly if I adjusted the seek parameters to force the server to pair me against higher rated opponents so I would lose more often, but that&#39;s a different story. . At any rate, what we&#39;re really interested in is the difference by move. . df.diff().mean(axis=1)[:50].plot(); . It seems quite noisy (it&#39;s not really plausible that I&#39;m great at playing move 20 but terrible at move 21, or whatever). This makes sense, as a single blunder that changes the evaluation by a large number like 10 could really impact the mean. I could try to address that by using the median. . df.diff().median(axis=1)[:50].plot(); . /Users/nate/.pyenv/versions/3.9.0b5/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input) . Hmm, still quite jagged. Since I&#39;m really interested in trends across phases of the game, not individual moves, it would make sense to apply some smoothing. One way to do that would be to use a rolling mean. . df.diff().mean(axis=1)[:60].rolling(10).mean().plot(); . The trend actually goes up as the game goes on! Maybe I&#39;m not as bad at the endgame as I thought? . But thinking about it more, if you win more often than you lose, there should be an upward trend not only in the evaluation, but also in the difference. This is the expected development as you convert a large advantage: +3 becomes +5 becomes +8, etc. While converting a big advantage is certainly better than blowing it, it&#39;s not really what I had in mind when I set out to evaluate my endgame play. It also makes the data sensitive to factors I have little control over, like when my opponent resigns. . Additionally, I was still concerned about large but meaningless differences in evaluations. For example, there isn&#39;t much difference between a +5 and +10 position in practical terms, but a difference of 5 will impact the mean quite a lot. I could adjust the clip value from 10 to 5, but that&#39;s still not ideal. I&#39;d like a +5 and +10 position to register as different, just not so different. I&#39;d also like the scaling to continue all the way down to 0. I think the difference between a +0 and +2 position is bigger than the difference between +2 and +4. Ideally, I&#39;d like something that: . Can take any number, positive or negative, as input. | Is more sensitive to differences closer to 0. | Still registers differences far from 0, but not as much. | . Is that sigmoid&#39;s music I hear??? . Why yes, sigmoid would seem to be perfect actually. It fits all our requirements and squishes the input into the range 0-1. Conveniently, this can be interpreted as expected points: 0 = certain loss, 1 = certain win. In fact, this is how AlphaZero evaluates positions, on a 0-1 scale representing expected score. . It will also handle the converting-a-win scenario very nicely. As long as we stay at a big plus score it won&#39;t really care, but if we blow it and get into a worse position, that will register as a big change. . def sigmoid(x): return 1 / (1 + np.exp(-x)) . Let&#39;s just plot the function as a quick visual reminder of what sigmoid does. . x = np.arange(-10, 10, 0.1) plt.plot(x, sigmoid(x)); . It&#39;s very sensitive to differences around 0, and very insensitive to differences far from 0, which is exactly what we want. . df_sigmoid = sigmoid(df) . Now I&#39;ll do the same plots I did with the raw evaluations. . df_sigmoid.mean(axis=1)[:50].plot(); . df_sigmoid.diff().mean(axis=1)[:50].plot(); . df_sigmoid.diff().mean(axis=1)[:50].rolling(10).mean().plot(); . Okay, this seems to show I do get weaker as the game goes on! But maybe I tortured the data until I got the result that I wanted? . Takeaways . The results were somewhat inconclusive: the raw data did not seem to show me getting weaker as the game went on, but after the sigmoid transformation they did. I&#39;m inclined to trust the sigmoid version more for the reasons discussed above, but my self-assessment of my endgame skills may have been overblown: the difference, if it exists, was not large or obvious. | When using summary statistics to compare engine evaluations across games, big-but-meaningless evaluation differences in clearly winning/clearly losing positions are a big problem. Using a sigmoid transformation is a promising way to combat this. | .",
            "url": "https://natesolon.github.io/blog/endgame",
            "relUrl": "/endgame",
            "date": " • Dec 27, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Chess Repertoire Explorer",
            "content": "MCO . In the hugely popular Netflix show Queen’s Gambit, the first book chess prodigy Beth Harmon receives from her mentor is MCO (Modern Chess Openings). . I don’t have my old copy of MCO - I must have lost or given it away - but I remember it well. A typical page looked like this: . . It was basically a giant catalog of opening variations: hundreds of pages, just like this. I think part of the appeal was the sense that something this dry and inscrutable must contain some really deep knowledge. . Intimidating as it was, MCO was the lightweight opening manual. Really serious players preferred ECO, the Encyclopedia of Chess Openings, which consisted of not one but five large volumes. The covers listed the title in multiple languages and the content had no explanatory text whatsoever, just a specialized set of symbols representing evaluations of positions. . The ponderous size and obscure format of these tomes obfuscated something important: On the scale that really counted, the scale of chess, even ECO was tiny. . Consider: Each side has 20 legal moves on move one. Thus, the number of possible sequences after just one complete move is 20 * 20 = 400. The number of possibilities after two full moves is on the order of 20^4 = 160,000. More actually, because many first moves increase the scope of the pieces and make more legal moves possible. And the possibilities increase exponentially from there. So as intimidating as it seems, even ECO only covers a tiny fraction of the possible variations. . Which in turn raises a question: Out of all the countless variations possible in chess, what good is it to memorize the relatively small selection of lines spelled out in these books? . There was never really a great answer to this question. I guess the reasoning was that the books covered the most important lines, as measured by chess logic and grandmaster practice. However, modern computer analysis shows that many of the lines and evaluations in the books were flawed. . This isn’t a knock on the authors, who made a heroic effort at an impossible task. Rather, it just underscores the futility of the underlying approach. It is not efficient or even possible to memorize every sequence of moves that might occur in your games. . Also, there’s the annoying fact that a chess game continues past the opening into the middlegame and endgame. Recalling the math outlined earlier, the branching nature of chess means that each move forward you nudge your repertoire increases the body of knowledge you need to memorize exponentially. . Planting a Tree . Looking at that page from MCO, it strikes me that the authors are struggling against the limitations of their format. The arrangement of the lines and how they relate to each other is confusing. It’s hardly obvious that the numbers along the left side of the page are move numbers whereas the numbers along the top are an index of different variations. It’s not easy to reason about my options in a given line by looking at this page. . Part of the problem is that this format is too beholden to a traditional chess scoresheet. When you play a tournament chess game, you write down all the moves. This is what they’re writing down during the tournament games in Queen’s Gambit. The finished scoresheet looks like this. . . Note that a scoresheet has a linear format: the moves go straight down the page in an unbroken sequence starting from move one. This is fine for a single game, but when we study chess, we’re concerned not just with what happened in one game, but what happened (or could happen) in many games. Thus, the structure of what we’re studying isn’t a line, but a series of branching paths. . This structure is called a tree and it’s very common in math and computer science. An early attempt at using a tree visualization for chess occurred in the famous book Think Like a Grandmaster by Alexander Kotov. . . This is a nice attempt to represent the tree-like structure of variations, but still suffers from some obvious problems. For example, it’s clearly not ideal for the text to be slanted at different angles, which contributes to the diagram being hard to read. . Fortunately, these days things are a lot easier. Now that we have computers and graphing libraries, we’re not limited to linear formats that are easy to write or print on a page. We can create visualizations that are rich, interactive, and adaptable. . Using a Sankey diagram to visualize your repertoire . To test these ideas in practice, I made an app that helps you prioritize which openings to study by using a chart type called a Sankey diagram to visualize your repertoire. I’d argue that there are two factors you should think about when deciding which opening to focus on: . How often the opening occurs in your games. Clearly, you don’t want to waste time on openings that hardly ever happen. . | How well you score in the opening. It makes sense to pay special attention to the openings where you’re struggling. . | So, which openings occur the most often in your games? And how do you score with your main openings? . These questions aren’t that easy to answer with the existing tools. The best way I know of to do this in ChessBase is: . Create a new database of the subset of games you’re interested in. For example, your white games from the past year. . | Select all the games in the database with Ctrl-A, then do Ctrl-Alt-Enter. (Good luck figuring that out from the documentation!) . | This takes you to a view where you can go through your repertoire move-by-move and see how you’ve scored in each line. Useful, but the only way to access the information is to toggle through one move at a time; there’s no top-level summary to let you see what’s going on in the big picture. . I wanted to create a way of visualizing your opening repertoire that would make it easy to answer these questions. The result was this app. It grabs your latest games from lichess and displays them in a way that makes it easy to see which openings occur the most often and how you’re doing in them. . . This kind of chart is known as a Sankey diagram. It’s used to visualize flows between various states, which are called nodes. In this case the nodes are positions and the flows are moves. . Nodes are color-coded white or black to show who made the last move, and move numbers are aligned vertically to facilitate comparison between lines. . The thickness of the flows represents how often that variation occurred. For example, a variation that only happened in one of your games will be a thin line, whereas a variation that happens frequently will be a thick flow. The flows are color-coded by how well you scored in that line: green represents a 100% score (you won every game), red represents a 0% score (you lost every game). . Based on the prioritization system introduced at the beginning of this article, you should focus on relatively thick, red areas, because these represent lines that happen a lot in your games and where you struggle. . You can use the app to create this diagram for the last 100 blitz games of any player on lichess. For example, here’s the chart for world champion Magnus Carlsen (DrNykterstein on lichess): . . Unsurprisingly, Magnus is doing pretty well, but in this sample he’s not scoring as well with the English (1. c4) as with 1. e4 or 1. d4. . The biggest thing that jumps out about this chart, of course, is just how many lines there are. This is both a feature and a bug. It’s a bug because it clutters the chart, making it harder to use for its intended purpose of evaluating your opening repertoire. However, it’s also a feature, because it reveals something true about chess that traditional ways of writing down moves obscure: namely, there are an insane number of possibilities. . I don’t know how many players will find this app to be a useful way of exploring their opening repertoire, but I’m confident that there’s a lot of room for tree-based techniques to improve how we visualize and think about chess. .",
            "url": "https://natesolon.github.io/blog/tree",
            "relUrl": "/tree",
            "date": " • Nov 21, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Poker Player to Data Scientist",
            "content": "I played poker for a living for seven years. About three years ago, I decided to quit and pursue a career in machine learning and data science. I’m now working full-time as a data scientist at reserved.ai. . This post is about the most important lessons from that journey. Since there’s already a lot of great resources out there about coding and math, I focused more on how to get a job without a standard technical background, and specific lessons from poker that carry over into data science. . People skills . In the course of playing poker a living for seven years I had to learn about various fields related to ML - statistics, probability, game theory - but I think the most relevant thing for getting a job in data science was actually just spending a lot of time sitting around a table with a diverse group of people and learning to get along with them. In poker, getting invited to the biggest games is often more important than being the best player. . I’m really grossed out by the term “networking” - it feels like reducing social interaction to something inauthentic and manipulative. Nonetheless, if you’re looking for a job, it pays to be a little strategic about forming social connections. . If I could pick just one thing that I think really helped me find a job, it would be doing informational interviews. I learned about this by reading Designing Your Life by Bill Burnett and Dave Evans. . I started reaching out to people I knew were doing interesting things in data science or machine learning and asking if they’d meet for coffee or lunch. I was kind of shocked how easy it was. Almost everyone I reached out to said yes, and often introduced me to new connections. . For example, I met a program manager at Sonos at a one-day data visualization class. From him I learned a lot about the day-to-day reality of working on data in a business setting. He introduced me to an engineer at Amazon who helped me prepare for coding interviews. . Some tips: . If you ask someone for help, remember that “No” is a valid answer. Be considerate and polite - apart from just being a good way to carry yourself in general, you may run into them again later. . | If someone doesn’t respond the first time, wait a week or so and try again. Many times people just don’t see an email or forget to respond. If they don’t respond a second time, it’s probably time to move on. . | Be respectful of other people’s time. I think 30 minutes is about what’s expected for a meeting like this. . | . Books aren’t where it’s at . A few weeks ago I was thinking about which resources I wished I knew about when I started learning about ML and I realized all my top choices are presented as videos: fast.ai, Weights &amp; Biases, and 3Blue1Brown. . Part of this may be my personal learning style - I often learn better by watching than by reading. But even so, I was surprised I couldn’t find a book I was really happy with. I’ve read, or at least looked through, a lot of the most famous introductory ML books, but I found they were outdated, or poorly organized, or the explanations didn’t make sense to me, or they assumed prior knowledge I thought many readers wouldn’t have. One way or another, I couldn’t find a book I was really happy with. . ML and poker are really similar in this regard. Cutting-edge information is passed through videos, forums, or groups of people working together. I think it’s because both fields are moving so fast: the theory completely changes every year or two. By the time you finish writing a book, it’s already out of date. . There are exceptions, of course. Play Optimal Poker is a new poker book that’s really well done. And if you’re reading this you probably know there’s a fast.ai book now. I haven’t had a chance to read it yet, but I’m very excited about it. . Keep it simple . We have a term in poker called FPS (“Fancy Play Syndrome”). This is when you reject the obvious play in favor of something fancy and complicated. It rarely works out well. . One amazing thing about poker right now is you can watch some of the best players in the world play and explain what they’re doing in real time. When I watch players like Ben Sulsky, Doug Polk, or Phil Galfond I’m often struck by how simple their thought process seems. Once you hear it, it seems obvious. What sets them apart is an ability to focus with laser-like precision on the most important factors for the current decision. . The ML version of FPS would be skipping linear regression and going straight to an RNN. The academic literature, in particular, is full of insanely complicated and hard-to-understand methodologies. In my experience so far, this is very far removed from working with data in a business context. For the most part you figure out a simple solution that works pretty well, then move on to the next urgent problem. . Dealing with failure . Maybe the biggest thing poker and ML have in common is this: you can make good choices, yet fail, over and over and over and over again. How you deal with this situation will have more to do with whether you ultimately succeed than anything else. . In poker someone can make a bad play and still beat you by hitting a lucky card. If this happens once, it’s easy enough to shrug off. But when you “run bad” for a long time - when the losing sessions extend into losing weeks or months - it’s hard to deal with, no matter how well you understand variance on a conceptual level. . Likewise, dealing with failure was what I found most challenging when I started learning about ML. Even simple things like setting up my environment and getting all the appropriate packages installed could take hours or days, where nothing I did seemed to work. I felt like an idiot and had no idea when it was going to end. . The obvious response is to persevere and tough it out. I think this is good advice, up to a point, but it needs to be balanced with a certain amount of levity. One of my poker coaches once gave me very good advice: “When you lose, the first thing you need to get back isn’t the money you lost, it’s your love of the game.” . While ML isn’t a game per se, it’s still helpful to have a playful mindset. This encourages creativity, which is important not just because it’s more fun, but because it will allow you to find better solutions more quickly. Try to see everything you do as an “experiment” where failure is normal, healthy, and productive. . I learned a lot by watching Rachel Tatman’s live coding streams. She makes a lot of mistakes, but iterates on them quickly and cheerfully. As they say in Designing Your Life, “Fail fast and fail forward.” . Conclusion . When I was doing informational interviews, one of the most common questions I asked was, “How big of a deal is it that I don’t have an academic background in this field?” What I heard back was pretty consistent: It might make it hard for me to get hired at some companies, but it wouldn’t prevent me from doing the work effectively. . For those trying to get a job in machine learning or data science, especially if you’re coming from a non-traditional background, I hope you’ve found something helpful here. .",
            "url": "https://natesolon.github.io/blog/poker-to-data-science",
            "relUrl": "/poker-to-data-science",
            "date": " • Mar 29, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Data scientist at Reserved.ai. . Former poker pro and chess master. . Interested in data, learning, and games. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://natesolon.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}